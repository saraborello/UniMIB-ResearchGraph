import streamlit as st
from langchain_core.messages import HumanMessage
from pipeline import graph  # Import the compiled graph from your orchestrator

# Initial configuration for the Streamlit app
st.set_page_config(
    page_title="Departmental Research Explorer",
    page_icon="🔍📚",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Title and description
st.title("🔍📚 Departmental Research Explorer")
st.markdown(
    """
    Welcome to the **Departmental Research Explorer**!
    This chatbot is designed to assist with exploring and understanding research activities at the University of Milano-Bicocca's Department of Computer Science. 
    Ask questions to identify research areas, analyze collaboration networks, and discover partnerships.
    """
)

# Sidebar with instructions
with st.sidebar:
    st.header("How it works:")
    st.markdown(
        """
        1. Enter your query in the text box.
        2. The chatbot processes your query using an intelligent pipeline.
        3. It retrieves relevant data, analyzes it, and generates a response.
        4. Intermediate steps are displayed with brief descriptions.
        """
    )
    st.markdown("---")
    st.markdown("### Example Queries:")
    st.markdown("- What are the main research areas, and how many publications are associated with each area? Order in a descendant way")
    st.markdown("- How are researchers collaborating on artificial intelligence?")
    st.markdown("- What partnerships exist between the department and external institutions?")
    st.markdown("---")
    st.info("💡 Use this interface to explore research activities effortlessly!")

# Manage session state for chat history
if "history" not in st.session_state:
    st.session_state.history = []

# Function to add a message to the history
def add_to_history(question, answer):
    st.session_state.history.append({"question": question, "answer": answer})

# Input for the query
query = st.text_input("💬 **Enter your question:**", value="", help="Type your query to get started.")

# Containers for output
st.markdown("### 📜 **Intermediate Steps:**")
intermediate_steps = st.container()

st.markdown("### 🧠 **Chat History:**")
chat_history = st.container()

# Loading message placeholder
loading_message = st.empty()

# Function to display intermediate steps with descriptive messages
def display_intermediate_steps(outputs):
    with intermediate_steps:
        for idx, (key, _) in enumerate(outputs):
            if idx == 0:
                message = "🔍 Analyzing research data to extract relevant information."
            elif idx == 1:
                message = "🤔 Thinking about the best response."
            else:
                message = "✅ Successfully processed the data."
            st.markdown(
                f"""
                <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin-bottom: 10px;">
                    <strong>Step {idx + 1}: Node <code>{key}</code></strong>
                    <p>{message}</p>
                </div>
                """,
                unsafe_allow_html=True,
            )

# Function to highlight numbers in the final response
def highlight_numbers(text):
    import re
    # Replace numbers with a green-colored version
    return re.sub(r"(\d+)", r"<span style='color: green;'>\1</span>", text)

# Execute the pipeline
if st.button("Submit Query") and query.strip():
    loading_message.info("⏳ Processing your query... Please wait.")
    inputs = {"messages": [HumanMessage(content=query)]}
    outputs = []

    try:
        # Run the pipeline and display intermediate steps
        for output in graph.stream(inputs):
            for key, value in output.items():
                outputs.append((key, value))

        # Display intermediate steps
        if outputs:
            display_intermediate_steps(outputs)

        # Extract and display the final response
        if outputs:
            final = outputs[-1]
            response = final[1].get("response", None)
            if response:
                # Highlight numbers in the response
                highlighted_response = highlight_numbers(response)
                add_to_history(query, highlighted_response)  # Add to history
            else:
                add_to_history(query, "⚠️ Unable to generate a response.")
        else:
            add_to_history(query, "⚠️ No output generated by the pipeline.")

    except Exception as e:
        # Error handling
        add_to_history(query, f"An error occurred: {e}")

    finally:
        # Remove the loading message
        loading_message.empty()

# Display chat history
with chat_history:
    for idx, entry in enumerate(st.session_state.history):
        st.markdown(
            f"""
            <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin-bottom: 10px;">
                <p><strong>Question {idx + 1}:</strong> {entry['question']}</p>
                <p><strong>Answer:</strong> {entry['answer']}</p>
            </div>
            """,
            unsafe_allow_html=True,
        )
